[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning con Tidymodels",
    "section": "",
    "text": "Tidymodels\n\n\n\n\n\n\n\ncode\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2022\n\n\nGustavo Bruges\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/knn-Wisconsin Breast Cancer/index.html",
    "href": "posts/knn-Wisconsin Breast Cancer/index.html",
    "title": "Tidymodels",
    "section": "",
    "text": "En essta sección aprenderemos sobre la clasificación mediante k-NN (vecinos más cercanos cercanos). A diferencia de muchos algoritmos de clasificación, k-nearest neighbors no realiza ningún aprendizaje. Simplemente almacena los datos de entrenamiento textualmente. Los ejemplos de prueba sin etiquetar se emparejan con los con los registros más similares del conjunto de entrenamiento mediante una función de distancia, y al ejemplo sin etiquetar se le asigna la etiqueta de sus vecinos.\nA pesar de que k-NN es un algoritmo muy sencillo, es capaz de abordar\ntareas extremadamente complejas, como la identificación de masas cancerosas.\nA pesar de la simplicidad de esta idea, los métodos de vecino más cercano son extremadamente potentes. Se han utilizado con éxito para:\n- Aplicaciones de visión por ordenador, como el reconocimiento óptico de caracteres y reconocimiento facial, tanto en imágenes fijas como en vídeo\n- Sistemas de recomendación que predicen si a una persona le gustará una película o una canción\n- Identificación de patrones en datos genéticos para detectar proteínas o enfermedades específicas.\nEn general, los clasificadores por vecino más próximo (k-NN) son adecuados para tareas de clasificación en las que las relaciones entre las características y las clases objetivo son numerosas, complicadas o extremadamente difíciles de entender, pero los elementos de clases similares tienden a ser bastante homogéneos."
  },
  {
    "objectID": "posts/knn-Wisconsin Breast Cancer/index.html#cargar-paquetes",
    "href": "posts/knn-Wisconsin Breast Cancer/index.html#cargar-paquetes",
    "title": "Tidymodels",
    "section": "Cargar paquetes",
    "text": "Cargar paquetes\n\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n\n✔ broom        1.0.0     ✔ recipes      1.0.1\n✔ dials        1.0.0     ✔ rsample      1.0.0\n✔ dplyr        1.0.9     ✔ tibble       3.1.8\n✔ ggplot2      3.3.6     ✔ tidyr        1.2.0\n✔ infer        1.0.2     ✔ tune         1.0.0\n✔ modeldata    1.0.1     ✔ workflows    1.0.0\n✔ parsnip      1.0.0     ✔ workflowsets 1.0.0\n✔ purrr        0.3.4     ✔ yardstick    1.0.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ readr   2.1.2     ✔ forcats 0.5.1\n✔ stringr 1.5.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(skimr)\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\n\nDatos de wisconsin data set:\nEl examen sistemático del cáncer de mama permite diagnosticar y tratar la enfermedad antes de que cause síntomas perceptibles. El proceso de detección precoz consiste en examinar el tejido mamario en busca de bultos o masas anormales. Si se detecta un bulto, se realiza una biopsia por aspiración con aguja fina, en la que se utiliza una aguja hueca para extraer una pequeña muestra de células de la masa. A continuación, el personal de salud examina las células al microscopio para determinar si la masa puede ser maligna o benigna.\nSi el aprendizaje automático pudiera automatizar la identificación de células cancerosas, supondría un beneficio considerable para el sistema sanitario.\nEs probable que los procesos automatizados de detección, lo que permitiría a los médicos dedicar menos tiempo al diagnóstico y más al tratamiento.\nA continuación veremos un plantearemos el algoritmo k-NN en el diánostico de cáncer de mama de muestras provenientes de Breast Cancer Wisconsin http://archive.ics.uci.edu/ml.\n\n\nCarga de los datos\n\nwbc <- read_csv(\"https://raw.githubusercontent.com/rspanhol/wisconsin-breast-cancer/main/wisconsin.csv\")\n\nNew names:\n• `` -> `...33`\n\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\nRows: 568 Columns: 33\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): diagnosis\ndbl (31): id, radius_mean, texture_mean, perimeter_mean, area_mean, smoothne...\nlgl  (1): ...33\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#Visionado de los datos\nglimpse(wbc)\n\nRows: 568\nColumns: 33\n$ id                      <dbl> 842302, 842517, 84300903, 84348301, 84358402, …\n$ diagnosis               <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"…\n$ radius_mean             <dbl> 17.990, 20.570, 19.690, 11.420, 20.290, 12.450…\n$ texture_mean            <dbl> 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.9…\n$ perimeter_mean          <dbl> 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, …\n$ area_mean               <dbl> 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, …\n$ smoothness_mean         <dbl> 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0…\n$ compactness_mean        <dbl> 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0…\n$ concavity_mean          <dbl> 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0…\n$ `concave points_mean`   <dbl> 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0…\n$ symmetry_mean           <dbl> 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087…\n$ fractal_dimension_mean  <dbl> 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0…\n$ radius_se               <dbl> 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.3345…\n$ texture_se              <dbl> 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.8902…\n$ perimeter_se            <dbl> 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.18…\n$ area_se                 <dbl> 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53.…\n$ smoothness_se           <dbl> 0.006399, 0.005225, 0.006150, 0.009110, 0.0114…\n$ compactness_se          <dbl> 0.049040, 0.013080, 0.040060, 0.074580, 0.0246…\n$ concavity_se            <dbl> 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, 0…\n$ `concave points_se`     <dbl> 0.015870, 0.013400, 0.020580, 0.018670, 0.0188…\n$ symmetry_se             <dbl> 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, 0…\n$ fractal_dimension_se    <dbl> 0.006193, 0.003532, 0.004571, 0.009208, 0.0051…\n$ radius_worst            <dbl> 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22.8…\n$ texture_worst           <dbl> 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27.6…\n$ perimeter_worst         <dbl> 184.60, 158.80, 152.50, 98.87, 152.20, 103.40,…\n$ area_worst              <dbl> 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6, …\n$ smoothness_worst        <dbl> 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.1791…\n$ compactness_worst       <dbl> 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.5249…\n$ concavity_worst         <dbl> 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, 0…\n$ `concave points_worst`  <dbl> 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, 0…\n$ symmetry_worst          <dbl> 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.3985…\n$ fractal_dimension_worst <dbl> 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, 0…\n$ ...33                   <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\nLimpieza inicial de los datos\nSe proceden a eliminar columnas que son innecesarias para el análisis, el identificador id y la última columna que contiene solamente valores NA, además se hace una modificación para que la varaible diagnosis sea de tipo categórica. Adicionalmente se corrigen los nombres cortos de variables con clean_names de janitor\n\nwbc <- wbc[-c(1,33)]\nglimpse(wbc)\n\nRows: 568\nColumns: 31\n$ diagnosis               <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"…\n$ radius_mean             <dbl> 17.990, 20.570, 19.690, 11.420, 20.290, 12.450…\n$ texture_mean            <dbl> 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.9…\n$ perimeter_mean          <dbl> 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, …\n$ area_mean               <dbl> 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, …\n$ smoothness_mean         <dbl> 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0…\n$ compactness_mean        <dbl> 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0…\n$ concavity_mean          <dbl> 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0…\n$ `concave points_mean`   <dbl> 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0…\n$ symmetry_mean           <dbl> 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087…\n$ fractal_dimension_mean  <dbl> 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0…\n$ radius_se               <dbl> 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.3345…\n$ texture_se              <dbl> 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.8902…\n$ perimeter_se            <dbl> 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.18…\n$ area_se                 <dbl> 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53.…\n$ smoothness_se           <dbl> 0.006399, 0.005225, 0.006150, 0.009110, 0.0114…\n$ compactness_se          <dbl> 0.049040, 0.013080, 0.040060, 0.074580, 0.0246…\n$ concavity_se            <dbl> 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, 0…\n$ `concave points_se`     <dbl> 0.015870, 0.013400, 0.020580, 0.018670, 0.0188…\n$ symmetry_se             <dbl> 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, 0…\n$ fractal_dimension_se    <dbl> 0.006193, 0.003532, 0.004571, 0.009208, 0.0051…\n$ radius_worst            <dbl> 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22.8…\n$ texture_worst           <dbl> 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27.6…\n$ perimeter_worst         <dbl> 184.60, 158.80, 152.50, 98.87, 152.20, 103.40,…\n$ area_worst              <dbl> 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6, …\n$ smoothness_worst        <dbl> 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.1791…\n$ compactness_worst       <dbl> 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.5249…\n$ concavity_worst         <dbl> 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, 0…\n$ `concave points_worst`  <dbl> 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, 0…\n$ symmetry_worst          <dbl> 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.3985…\n$ fractal_dimension_worst <dbl> 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, 0…\n\n\nLas 30 medidas numéricas comprenden la media, el error estándar y el peor valor (es decir, el mayor) de 10 características diferentes de los núcleos celulares digitalizados Estas incluyen:\n- Radio\n- Textura\n- Perímetro\n- Superficie\n- Suavidad\n- Compacidad\n- Concavidad\n- Puntos cóncavos\n- Simetría\n- Dimensión fractal\n\n#Limpiar nombres de variables\nwbc <- wbc %>% clean_names()\nglimpse(wbc)\n\nRows: 568\nColumns: 31\n$ diagnosis               <chr> \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"…\n$ radius_mean             <dbl> 17.990, 20.570, 19.690, 11.420, 20.290, 12.450…\n$ texture_mean            <dbl> 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.9…\n$ perimeter_mean          <dbl> 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, …\n$ area_mean               <dbl> 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, …\n$ smoothness_mean         <dbl> 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0…\n$ compactness_mean        <dbl> 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0…\n$ concavity_mean          <dbl> 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0…\n$ concave_points_mean     <dbl> 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0…\n$ symmetry_mean           <dbl> 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087…\n$ fractal_dimension_mean  <dbl> 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0…\n$ radius_se               <dbl> 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.3345…\n$ texture_se              <dbl> 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.8902…\n$ perimeter_se            <dbl> 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.18…\n$ area_se                 <dbl> 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53.…\n$ smoothness_se           <dbl> 0.006399, 0.005225, 0.006150, 0.009110, 0.0114…\n$ compactness_se          <dbl> 0.049040, 0.013080, 0.040060, 0.074580, 0.0246…\n$ concavity_se            <dbl> 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, 0…\n$ concave_points_se       <dbl> 0.015870, 0.013400, 0.020580, 0.018670, 0.0188…\n$ symmetry_se             <dbl> 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, 0…\n$ fractal_dimension_se    <dbl> 0.006193, 0.003532, 0.004571, 0.009208, 0.0051…\n$ radius_worst            <dbl> 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22.8…\n$ texture_worst           <dbl> 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27.6…\n$ perimeter_worst         <dbl> 184.60, 158.80, 152.50, 98.87, 152.20, 103.40,…\n$ area_worst              <dbl> 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6, …\n$ smoothness_worst        <dbl> 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.1791…\n$ compactness_worst       <dbl> 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.5249…\n$ concavity_worst         <dbl> 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, 0…\n$ concave_points_worst    <dbl> 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, 0…\n$ symmetry_worst          <dbl> 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.3985…\n$ fractal_dimension_worst <dbl> 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, 0…\n\n#Convertir variable diagnosis a categóricas\n\nwbc <- wbc %>% \n         mutate(diagnosis = factor(diagnosis))\n\nwbc <- wbc %>% \n  mutate(diagnosis = fct_relevel(diagnosis, \"M\"))\n\nwbc %>% count(diagnosis)\n\n# A tibble: 2 × 2\n  diagnosis     n\n  <fct>     <int>\n1 M           212\n2 B           356\n\n\n\n\nAnálisis Exploratorio de los datos\nUsamos skim() de skimr para una estadística univariada de los datos\n\nskim(wbc)\n\n\nData summary\n\n\nName\nwbc\n\n\nNumber of rows\n568\n\n\nNumber of columns\n31\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n30\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ndiagnosis\n0\n1\nFALSE\n2\nB: 356, M: 212\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nradius_mean\n0\n1\n14.14\n3.52\n6.98\n11.71\n13.38\n15.80\n28.11\n▂▇▃▁▁\n\n\ntexture_mean\n0\n1\n19.28\n4.30\n9.71\n16.17\n18.84\n21.78\n39.28\n▃▇▃▁▁\n\n\nperimeter_mean\n0\n1\n92.05\n24.25\n43.79\n75.20\n86.29\n104.15\n188.50\n▃▇▃▁▁\n\n\narea_mean\n0\n1\n655.72\n351.66\n143.50\n420.30\n551.40\n784.15\n2501.00\n▇▃▂▁▁\n\n\nsmoothness_mean\n0\n1\n0.10\n0.01\n0.06\n0.09\n0.10\n0.11\n0.16\n▂▇▅▁▁\n\n\ncompactness_mean\n0\n1\n0.10\n0.05\n0.02\n0.07\n0.09\n0.13\n0.35\n▇▇▂▁▁\n\n\nconcavity_mean\n0\n1\n0.09\n0.08\n0.00\n0.03\n0.06\n0.13\n0.43\n▇▃▂▁▁\n\n\nconcave_points_mean\n0\n1\n0.05\n0.04\n0.00\n0.02\n0.03\n0.07\n0.20\n▇▃▂▁▁\n\n\nsymmetry_mean\n0\n1\n0.18\n0.03\n0.11\n0.16\n0.18\n0.20\n0.30\n▁▇▅▁▁\n\n\nfractal_dimension_mean\n0\n1\n0.06\n0.01\n0.05\n0.06\n0.06\n0.07\n0.10\n▆▇▂▁▁\n\n\nradius_se\n0\n1\n0.41\n0.28\n0.11\n0.23\n0.32\n0.48\n2.87\n▇▁▁▁▁\n\n\ntexture_se\n0\n1\n1.22\n0.55\n0.36\n0.83\n1.11\n1.47\n4.88\n▇▅▁▁▁\n\n\nperimeter_se\n0\n1\n2.87\n2.02\n0.76\n1.61\n2.29\n3.36\n21.98\n▇▁▁▁▁\n\n\narea_se\n0\n1\n40.37\n45.52\n6.80\n17.85\n24.57\n45.24\n542.20\n▇▁▁▁▁\n\n\nsmoothness_se\n0\n1\n0.01\n0.00\n0.00\n0.01\n0.01\n0.01\n0.03\n▇▃▁▁▁\n\n\ncompactness_se\n0\n1\n0.03\n0.02\n0.00\n0.01\n0.02\n0.03\n0.14\n▇▃▁▁▁\n\n\nconcavity_se\n0\n1\n0.03\n0.03\n0.00\n0.02\n0.03\n0.04\n0.40\n▇▁▁▁▁\n\n\nconcave_points_se\n0\n1\n0.01\n0.01\n0.00\n0.01\n0.01\n0.01\n0.05\n▇▇▁▁▁\n\n\nsymmetry_se\n0\n1\n0.02\n0.01\n0.01\n0.02\n0.02\n0.02\n0.08\n▇▃▁▁▁\n\n\nfractal_dimension_se\n0\n1\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.03\n▇▁▁▁▁\n\n\nradius_worst\n0\n1\n16.28\n4.83\n7.93\n13.02\n14.97\n18.79\n36.04\n▆▇▃▁▁\n\n\ntexture_worst\n0\n1\n25.67\n6.15\n12.02\n21.08\n25.41\n29.68\n49.54\n▃▇▆▁▁\n\n\nperimeter_worst\n0\n1\n107.35\n33.57\n50.41\n84.15\n97.66\n125.53\n251.20\n▇▇▃▁▁\n\n\narea_worst\n0\n1\n881.66\n569.28\n185.20\n515.68\n686.55\n1085.00\n4254.00\n▇▂▁▁▁\n\n\nsmoothness_worst\n0\n1\n0.13\n0.02\n0.07\n0.12\n0.13\n0.15\n0.22\n▂▇▇▂▁\n\n\ncompactness_worst\n0\n1\n0.25\n0.16\n0.03\n0.15\n0.21\n0.34\n1.06\n▇▅▁▁▁\n\n\nconcavity_worst\n0\n1\n0.27\n0.21\n0.00\n0.12\n0.23\n0.38\n1.25\n▇▅▂▁▁\n\n\nconcave_points_worst\n0\n1\n0.11\n0.07\n0.00\n0.06\n0.10\n0.16\n0.29\n▅▇▅▃▁\n\n\nsymmetry_worst\n0\n1\n0.29\n0.06\n0.16\n0.25\n0.28\n0.32\n0.66\n▅▇▁▁▁\n\n\nfractal_dimension_worst\n0\n1\n0.08\n0.02\n0.06\n0.07\n0.08\n0.09\n0.21\n▇▃▁▁▁\n\n\n\n\n\nYa que tenemos una variable de salida categórica, haremos una exploración de los datos númericos y compararemos esos datos númericos asociados a las células benignas y malignas\n\nwbc %>% pivot_longer(cols=-diagnosis, names_to = \"parametro\", values_to = \"valor\") %>% \n  ggplot(aes(diagnosis, valor, fill= diagnosis))+\n  geom_boxplot() + facet_wrap(~parametro, scales = \"free\")\n\n\n\n\nAdicionalmente haremos la evaluación a través de ggpairs de GGally\n\nggpairs(wbc[1:8], aes(color = diagnosis))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nLa evaluación diagnostica permite diferenciar una clara separación entre células malignas y benignas asociada a los parametros descritos\n\n\nMachine Learning con Tidymodels:\nAplicaremos el flujo de trabajo del ecositema Tidymodels:\n\nDivisión de los datos en grupo de entrenamiento y prueba\n\nset.seed(1970)\nwbc_split <- wbc %>% \n                 initial_split(prop = 0.75, strata = diagnosis)\n\nwbc_train <- training(wbc_split)\nwbc_test <- testing(wbc_split)\n\n#Evaluación de la dimensión de los dos grupos de datos\ndim(wbc_train)\n\n[1] 426  31\n\ndim(wbc_test)\n\n[1] 142  31\n\n\n\n\n\nFeature Engeneerigng: Preparación de los datos para aplicación del algoritmo knn\n\n\n¿notas algo problemático en los\nRecuerda que el cálculo de la distancia para k-NN depende en gran medida de la escala de medición de las características de entrada.. Dado que la suavidad oscila entre 0,05 y 0,16 mientras que el área oscila entre 143,5 y 2501,0, el impacto del área será mucho mayor que el de la suavidad en el cálculo de la distancia.. Esto podría causar problemas para nuestro clasificador, así que vamos a aplicar la normalización para reescalar las características a un estándar usando el paquete recipes()\n\n#Construir el recipe\n# Se usará la variable diagnosis como variable respuesta, los datos numéricos se normalizarán con step_normalize\nwbc_recipe <- recipe(diagnosis ~., data= wbc_train) %>% \n                  step_normalize(all_numeric()) #normalización\n\n#Imprimir el objeto wbc_recipe\nwbc_recipe\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         30\n\nOperations:\n\nCentering and scaling for all_numeric()\n\n\nEl objeto recipe contiene los procedimientos que se aplicarán al conjunto de variables así como el papel de cada una de las variables cuando se aplique el algoritmo. El recipe debe prepararse y aplicar luego a los datos de entreanimiento y prueba\n\nwbc_recipe_prep <- wbc_recipe %>% \n  prep(training = wbc_train)\n\n#Baking\nwbc_training_baked <- wbc_recipe_prep %>% \n  bake(new_data = NULL)\n\n#Datos de entrenamiento normalizados\nwbc_training_baked  %>% glimpse()\n\nRows: 426\nColumns: 31\n$ radius_mean             <dbl> -0.1695881, -0.3014030, -1.3261198, -0.3157306…\n$ texture_mean            <dbl> -1.1222690, -0.8194853, -1.5528948, -0.2116749…\n$ perimeter_mean          <dbl> -0.1884909, -0.2646714, -1.3174604, -0.3903899…\n$ area_mean               <dbl> -0.251162420, -0.382978983, -1.083628145, -0.3…\n$ smoothness_mean         <dbl> 0.12867392, 0.81233997, 0.45325688, -0.4317773…\n$ compactness_mean        <dbl> -0.4365584, 0.4310362, -0.7472677, -1.2646738,…\n$ concavity_mean          <dbl> -0.2859009, -0.5474374, -0.7485810, -0.7977439…\n$ concave_points_mean     <dbl> -0.02877076, -0.46226312, -0.73050436, -0.5107…\n$ symmetry_mean           <dbl> 0.293353263, 0.599154999, 0.032303000, -1.2654…\n$ fractal_dimension_mean  <dbl> -0.70969400, 0.73804585, 0.86827317, -0.575310…\n$ radius_se               <dbl> -0.46481050, -0.76647420, -0.43845500, -0.7711…\n$ texture_se              <dbl> -0.75450252, -0.82872674, -0.41296224, 2.06456…\n$ perimeter_se            <dbl> -0.37735994, -0.70475776, -0.44962998, -0.8080…\n$ area_se                 <dbl> -0.34735388, -0.53595857, -0.51410673, -0.5467…\n$ smoothness_se           <dbl> 0.55631329, -0.93930882, 0.94829306, -0.851935…\n$ compactness_se          <dbl> -0.6250921, -0.3703322, -0.6413781, -1.1893445…\n$ concavity_se            <dbl> -0.2661595, -0.4815811, -0.3918482, -0.5925748…\n$ concave_points_se       <dbl> 0.211472264, -0.835956215, 0.378180100, -0.026…\n$ symmetry_se             <dbl> -0.058771027, -0.444403061, 0.001244554, 0.823…\n$ fractal_dimension_se    <dbl> -0.5510642, -0.5046197, -0.3028652, -0.7453876…\n$ radius_worst            <dbl> -0.24482758, -0.37141214, -1.25750408, -0.6204…\n$ texture_worst           <dbl> -1.03345162, -0.83874932, -1.60331201, -0.4715…\n$ perimeter_worst         <dbl> -0.22923319, -0.33699461, -1.26117565, -0.6841…\n$ area_worst              <dbl> -0.29772223, -0.43832718, -0.98820230, -0.5857…\n$ smoothness_worst        <dbl> 0.525580669, -0.023824905, 0.027681868, -1.491…\n$ compactness_worst       <dbl> -0.5051461, 0.1326670, -0.9025870, -1.3388817,…\n$ concavity_worst         <dbl> -0.18440526, -0.41943689, -0.89105137, -1.0806…\n$ concave_points_worst    <dbl> 0.2081505, -0.6518532, -0.8141122, -1.0006487,…\n$ symmetry_worst          <dbl> 0.12140300, 0.45504464, -0.72801315, -1.474274…\n$ fractal_dimension_worst <dbl> -0.63308242, -0.13651592, -0.35685387, -1.2188…\n$ diagnosis               <fct> B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B…\n\n#Datos de prueba normalizados\nwbc_test_baked <- wbc_recipe_prep %>% \n  bake(new_data = wbc_test)\n\nwbc_test_baked %>% glimpse()\n\nRows: 142\nColumns: 31\n$ radius_mean             <dbl> 1.59271860, 1.18008093, 0.47229269, -0.1151428…\n$ texture_mean            <dbl> 0.42304963, 0.13820860, -0.33054553, 0.7280762…\n$ perimeter_mean          <dbl> 1.58239267, 1.14945452, 0.48339582, 0.06710913…\n$ area_mean               <dbl> 1.56152885, 1.09746622, 0.36009063, -0.2169983…\n$ smoothness_mean         <dbl> 0.960197715, -0.093816780, 0.080092091, 1.2066…\n$ compactness_mean        <dbl> 1.055491792, 0.089388829, 0.472793148, 2.37273…\n$ concavity_mean          <dbl> 1.34570790, 0.28883070, 0.12462169, 1.53786739…\n$ concave_points_mean     <dbl> 2.04893144, 0.65065265, 0.44467243, 0.81279073…\n$ symmetry_mean           <dbl> 0.97954252, -0.04601208, 0.13299382, 0.9795425…\n$ fractal_dimension_mean  <dbl> -0.38689650, -0.74294353, -0.27190855, 1.94472…\n$ radius_se               <dbl> 1.22942116, 0.16487240, 0.37536030, -0.6706683…\n$ texture_se              <dbl> -0.75758764, -0.78245003, -0.39826258, -0.0641…\n$ perimeter_se            <dbl> 0.84832048, 0.16684799, 0.35310097, -0.3759048…\n$ area_se                 <dbl> 1.14769368, 0.29653279, 0.30183663, -0.4396407…\n$ smoothness_se           <dbl> -0.23586960, -0.86495601, -0.36573003, -0.1402…\n$ compactness_se          <dbl> 0.85577249, -0.67046030, 0.88776289, 1.9783446…\n$ concavity_se            <dbl> 0.18563169, -0.30774308, -0.13984558, 0.707458…\n$ concave_points_se       <dbl> 1.379999832, -0.222597196, 0.159572655, 0.7037…\n$ symmetry_se             <dbl> 0.285999334, -0.838973585, -0.023017064, -0.08…\n$ fractal_dimension_se    <dbl> 0.29273811, -0.59602237, 0.13408396, 1.6013561…\n$ radius_worst            <dbl> 1.51075504, 1.36756922, 0.85708066, -0.2614288…\n$ texture_worst           <dbl> -0.04094478, 0.29622261, 0.23607069, 0.9848039…\n$ perimeter_worst         <dbl> 1.34688951, 1.36778508, 0.86927657, 0.04240917…\n$ area_worst              <dbl> 1.44076126, 1.26130265, 0.72641146, -0.3212435…\n$ smoothness_worst        <dbl> 0.54274959, 0.53416513, 0.33672250, 1.43124142…\n$ compactness_worst       <dbl> 1.066812087, 0.005485953, 1.934187070, 3.27976…\n$ concavity_worst         <dbl> 0.80930849, 0.47086294, 0.55594439, 1.95579280…\n$ concave_points_worst    <dbl> 1.9628836, 1.1976847, 1.0102264, 1.6217709, 0.…\n$ symmetry_worst          <dbl> 1.1465048, 0.2600174, 1.4350162, 1.1191043, 0.…\n$ fractal_dimension_worst <dbl> 0.17249461, -0.03709514, 1.09791399, 3.1561928…\n$ diagnosis               <fct> M, M, M, M, M, M, M, M, M, M, M, M, B, B, B, B…\n\n\n\n\nConstruccón del modelo de clasificación knn\n\n#Se especifica el modelo\nknn_model <- nearest_neighbor(neighbors = 21) %>% \n  set_engine(\"kknn\") %>% \n  set_mode(\"classification\")\n\n\nknn_model\n\nK-Nearest Neighbor Model Specification (classification)\n\nMain Arguments:\n  neighbors = 21\n\nComputational engine: kknn \n\n\n\nAjuste del modelo a los datos de entrenamiento\n\nknn_fit <- knn_model %>% \n             fit(diagnosis~., data= wbc_training_baked)\n\nknn_fit\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = diagnosis ~ ., data = data, ks = min_rows(21,     data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.03286385\nBest kernel: optimal\nBest k: 21\n\n\n\n\n\nEvaluación de la predicción del modelo\nSe predicen las clases suministrando la información de los datos de entrenamiento\n\nclases_preds <- predict(knn_fit, new_data = wbc_test_baked,\n                        type = \"class\")\nclases_preds\n\n# A tibble: 142 × 1\n   .pred_class\n   <fct>      \n 1 M          \n 2 M          \n 3 M          \n 4 M          \n 5 M          \n 6 M          \n 7 M          \n 8 M          \n 9 M          \n10 M          \n# … with 132 more rows\n\n\nSe predicen las probabilidades\n\nprob_preds <- predict(knn_fit, new_data = wbc_test_baked,\n                        type = \"prob\")\n\nprob_preds\n\n# A tibble: 142 × 2\n   .pred_M .pred_B\n     <dbl>   <dbl>\n 1   1      0     \n 2   1      0     \n 3   0.955  0.0453\n 4   0.965  0.0351\n 5   0.836  0.164 \n 6   1      0     \n 7   1      0     \n 8   1      0     \n 9   1      0     \n10   0.689  0.311 \n# … with 132 more rows\n\n\n\n\nMétricas del modelo\n\n#se crea una data.frame/tibble de resultados conteniendo los valores actuales (truth) y los valores predichos del modelo como clases y probabilidades\n\nresultados <- wbc_test %>% select(diagnosis) %>% \n                bind_cols(clases_preds) %>% \n                bind_cols(prob_preds)\n\nresultados\n\n# A tibble: 142 × 4\n   diagnosis .pred_class .pred_M .pred_B\n   <fct>     <fct>         <dbl>   <dbl>\n 1 M         M             1      0     \n 2 M         M             1      0     \n 3 M         M             0.955  0.0453\n 4 M         M             0.965  0.0351\n 5 M         M             0.836  0.164 \n 6 M         M             1      0     \n 7 M         M             1      0     \n 8 M         M             1      0     \n 9 M         M             1      0     \n10 M         M             0.689  0.311 \n# … with 132 more rows\n\n\n\nMatriz de Confusión\n\nconf_mat(resultados, truth = diagnosis, estimate = .pred_class) %>% autoplot(\"heatmap\")\n\n\n\n\n\n\nAccurracy , Área bajo la curva, sensibilidad y especificidad\n\nmetricas_wbc <- metric_set(accuracy, roc_auc, sens, specificity)\n\n\nmetricas_wbc(resultados, truth = diagnosis, estimate = .pred_class, .pred_M)\n\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary         0.972\n2 sens        binary         0.925\n3 specificity binary         1    \n4 roc_auc     binary         0.997\n\n\n\n\n\nCurva ROC\nUna curva ROC (acrónimo de Receiver Operating Characteristic, o Característica Operativa del Receptor) es una representación gráfica de la sensibilidad frente a la especificidad para un sistema clasificador binario según se varía el umbral de discriminación.\n\nroc_curve(resultados, truth = diagnosis, estimate = .pred_M) %>% autoplot()"
  },
  {
    "objectID": "posts/knn-Wisconsin Breast Cancer/index.html#conclusiones",
    "href": "posts/knn-Wisconsin Breast Cancer/index.html#conclusiones",
    "title": "Tidymodels",
    "section": "Conclusiones",
    "text": "Conclusiones\nEl algoritmo k-nearest neighbor (k-NN) es uno de los más simples y más utilizados en el aprendizaje automático. En este jemplo práctico se muestra una buena predicción del modelo, sin embargo, aunque es fácil de entender e implementar, tiene algunas desventajas:\nEl rendimiento del k-NN puede ser lento en grandes conjuntos de datos debido a la necesidad de almacenar todo el conjunto de datos y calcular la distancia para cada instancia de prueba durante la clasificación.\nEl k-NN es sensible a la escala de las características. Las características con una escala más grande tendrán un mayor peso en la distancia y, por lo tanto, tendrán un mayor impacto en la clasificación. Esto puede llevar a resultados no deseados si no se preprocesan adecuadamente los datos.\nEl k-NN no proporciona una forma de ajustar la complejidad del modelo. El valor de k se elige de forma empírica y no hay una manera de saber cuál es el mejor valor para k sin probar varios valores diferentes.\nEl k-NN es propenso a la interferencia de ruido en los datos. Las instancias de ruido o outliers pueden tener un gran impacto en los vecinos más cercanos y, por lo tanto, en la clasificación.\nEl k-NN no proporciona una representación explícita de los patrones en los datos. Aunque es útil para hacer predicciones, no proporciona una comprensión de cómo se realizan las prediccio.\nAquí usamos un criterio empírico paa elegir el valor de k vecinos, es importante considerar otras aproximaciones ya que la aproximación empírica se basa en la experiencia de ciertos conjunto de datos. Por otra parte se hizo una partición de los datos basados en un solo conjunto de entrenamiento y un conjunto de prueba; esto puede limitar el desarrollo del modelo por lo que es importante considerar otras aproximaciones que presentaremos en otra sección"
  },
  {
    "objectID": "posts/knn-Wisconsin Breast Cancer/index.html#bibliografía",
    "href": "posts/knn-Wisconsin Breast Cancer/index.html#bibliografía",
    "title": "Tidymodels",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nFix, E.; Hodges, J.L. (1989). «(1951): An Important Contribution to Nonparametric Discriminant Analysis and Density Estimation: Commentary on Fix and Hodges (1951)». International Statistical Review / Revue Internationale de Statistique 57 (3): 233-238. doi:10.2307/1403796..\n↑ Piryonesi, S. Madeh; El-Diraby, Tamer E. (2020-06). «Role of Data Analytics in Infrastructure Asset Management: Overcoming Data Size and Quality Problems». Journal of Transportation Engineering, Part B: Pavements (en inglés) 146 (2): 04020022. ISSN 2573-5438. doi:10.1061/JPEODX.0000175. Consultado el 7 de agosto de 2020.\n↑ Hastie, Trevor.; Friedman, J. H. (Jerome H.) (2001). The elements of statistical learning : data mining, inference, and prediction : with 200 full-color illustrations. Springer. ISBN 0-387-95284-5. OCLC 46809224. Consultado el 7 de agosto de 2020.\nKuhn, M., & Silge, J. (2022). Tidy Modeling with R. ” O’Reilly Media, Inc.”.https://www.tidymodels.org/books/\nIsmail Taha and Joydeep Ghosh. Characterization of the Wisconsin Breast cancer Database Using a Hybrid Symbolic-Connectionist System. Proceedings of ANNIE. 1996"
  }
]